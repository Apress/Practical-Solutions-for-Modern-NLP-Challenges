{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses a pre-trained language model (T5) for text generation\n",
    "# Implements a Flask API for serving predictions\n",
    "# Includes basic error handling and logging\n",
    "# Uses configuration for model parameters\n",
    "# Demonstrates multi-threading for running the Flask app in Colab\n",
    "\n",
    "# it's recommended to build modular code 1.Separate the code into different modules (e.g., model.py, api.py, config.py)\n",
    "#2.Use a main.py file to tie everything together\n",
    "\n",
    "# industry level development and best practices\n",
    "# Modularity: Split code into separate modules (e.g., model.py, api.py, config.py) for better organization.\n",
    "# Configuration Management: Use tools like python-dotenv or hydra for cleaner config handling.\n",
    "# Experiment Tracking: Integrate MLflow or Weights & Biases for model versioning and tracking.\n",
    "# Input/Output Handling: Add robust input validation, preprocessing, and output postprocessing.\n",
    "# Caching: Use Redis or Memcached to cache frequent requests.\n",
    "# Monitoring: Add comprehensive logging and monitoring with Prometheus or Grafana.\n",
    "# Testing: Implement unit tests, integration tests, and CI/CD pipelines.\n",
    "# Performance: Optimize inference with batching or model quantization.\n",
    "# Scalability: Design for horizontal scaling (e.g., Kubernetes).\n",
    "# Documentation: Add detailed docstrings and API documentation.\n",
    "\n",
    "\n",
    "!pip install transformers torch flask datasets pyyaml\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from flask import Flask, request, jsonify\n",
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "from threading import Thread\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'api_key': 'YOUR_SIMULATED_API_KEY',\n",
    "    'model_name': 't5-base',\n",
    "    'max_length': 100,\n",
    "    'temperature': 0.8,\n",
    "    'top_k': 50,\n",
    "    'top_p': 0.95,\n",
    "    'num_beams': 5,\n",
    "    'no_repeat_ngram_size': 2,\n",
    "    'repetition_penalty': 1.5,\n",
    "    'host': '0.0.0.0',\n",
    "    'port': 5001\n",
    "}\n",
    "\n",
    "API_KEY = config['api_key']\n",
    "\n",
    "class ContentGenerator:\n",
    "    def __init__(self, model_name=config['model_name']):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def generate_content(self, product_description, target_audience, desired_tone, max_length=config['max_length']):\n",
    "        try:\n",
    "            prompt = f\"Write a {desired_tone} marketing copy for {product_description} targeting {target_audience}.\"\n",
    "            input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids.to(self.model.device)\n",
    "            output = self.model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_length,\n",
    "                temperature=config['temperature'],\n",
    "                top_k=config['top_k'],\n",
    "                top_p=config['top_p'],\n",
    "                num_beams=config['num_beams'],\n",
    "                no_repeat_ngram_size=config['no_repeat_ngram_size'],\n",
    "                repetition_penalty=config['repetition_penalty']\n",
    "            )\n",
    "            generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            return generated_text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating content: {e}\")\n",
    "            raise e\n",
    "\n",
    "# Flask app setup\n",
    "app = Flask(__name__)\n",
    "content_generator = ContentGenerator()\n",
    "\n",
    "def authenticate(request):\n",
    "    api_key = request.headers.get(\"X-Api-Key\")\n",
    "    return api_key == API_KEY\n",
    "\n",
    "@app.route(\"/generate\", methods=[\"POST\"])\n",
    "def generate():\n",
    "    if not authenticate(request):\n",
    "        return jsonify({\"error\": \"Unauthorized\"}), 401\n",
    "\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        product_description = data.get(\"product_description\")\n",
    "        target_audience = data.get(\"target_audience\")\n",
    "        desired_tone = data.get(\"desired_tone\")\n",
    "\n",
    "        if not all([product_description, target_audience, desired_tone]):\n",
    "            return jsonify({\"error\": \"Missing required parameters\"}), 400\n",
    "\n",
    "        content = content_generator.generate_content(product_description, target_audience, desired_tone)\n",
    "\n",
    "        logger.info(f\"Generated content for product: {product_description}, audience: {target_audience}, tone: {desired_tone}\")\n",
    "\n",
    "        return jsonify({\"content\": content})\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating content: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Run the app in a separate thread\n",
    "def run_app():\n",
    "    app.run(debug=False, host=config['host'], port=config['port'])\n",
    "\n",
    "thread = Thread(target=run_app)\n",
    "thread.start()\n",
    "\n",
    "# Wait for the app to start\n",
    "time.sleep(5)\n",
    "\n",
    "# Test the API\n",
    "headers = {\"X-Api-Key\": API_KEY}\n",
    "data = {\"product_description\": \"a new AI-powered chatbot\", \"target_audience\": \"businesses\", \"desired_tone\": \"informative\"}\n",
    "\n",
    "response = requests.post(f\"http://{config['host']}:{config['port']}/generate\", headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Generated content:\", response.json()[\"content\"])\n",
    "else:\n",
    "    print(\"Error:\", response.json())\n",
    "\n",
    "# Additional product examples to test\n",
    "product_examples = [\n",
    "    \"a sustainable clothing line for eco-conscious consumers\",\n",
    "    \"a new AI-powered fitness tracker\",\n",
    "    \"an online course for learning data science\",\n",
    "    \"a subscription box for organic pet food\",\n",
    "    \"a productivity app for managing tasks and projects\",\n",
    "]\n",
    "\n",
    "for product_description in product_examples:\n",
    "    data = {\"product_description\": product_description, \"target_audience\": \"young adults\", \"desired_tone\": \"persuasive\"}\n",
    "    response = requests.post(f\"http://{config['host']}:{config['port']}/generate\", headers=headers, json=data)\n",
    "    print(f\"\\nProduct: {product_description}\")\n",
    "    print(\"Generated content:\", response.json().get(\"content\", \"Error: \" + str(response.json())))\n",
    "\n",
    "# Stop the Flask app\n",
    "import os\n",
    "import signal\n",
    "os.kill(os.getpid(), signal.SIGINT)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
