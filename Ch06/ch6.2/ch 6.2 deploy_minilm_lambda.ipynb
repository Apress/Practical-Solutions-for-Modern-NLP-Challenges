{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57af4f9",
   "metadata": {},
   "source": [
    "# Deploying MiniLM on AWS Lambda for Real-Time QA\n",
    "This notebook walks through packaging and deploying a MiniLM model to AWS Lambda using container images for low-latency question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbb74f",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies and Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f329f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch --quiet\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = \"deepset/minilm-uncased-squad2\"\n",
    "os.makedirs(\"minilm_model\", exist_ok=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.save_pretrained(\"minilm_model\")\n",
    "model.save_pretrained(\"minilm_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421be2a",
   "metadata": {},
   "source": [
    "## Step 2: Create `handler.py` for Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed418155",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler_code = '''\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch, json\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"/var/task/minilm_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/var/task/minilm_model\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    body = json.loads(event.get(\"body\", \"{}\"))\n",
    "    question = body.get(\"question\", \"\")\n",
    "    context_text = body.get(\"context\", \"\")\n",
    "\n",
    "    inputs = tokenizer(question, context_text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "    answer = tokenizer.convert_tokens_to_string(\n",
    "        tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps({\"answer\": answer})\n",
    "    }\n",
    "'''\n",
    "\n",
    "with open(\"minilm_model/handler.py\", \"w\") as f:\n",
    "    f.write(handler_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92a78c",
   "metadata": {},
   "source": [
    "## Step 3: Create a Dockerfile for Lambda Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile = '''\n",
    "FROM public.ecr.aws/lambda/python:3.9\n",
    "\n",
    "# Install dependencies\n",
    "RUN pip install torch transformers --quiet\n",
    "\n",
    "# Copy model and handler\n",
    "COPY minilm_model /var/task/minilm_model\n",
    "\n",
    "CMD [\"minilm_model.handler.lambda_handler\"]\n",
    "'''\n",
    "with open(\"minilm_model/Dockerfile\", \"w\") as f:\n",
    "    f.write(dockerfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133b0d9",
   "metadata": {},
   "source": [
    "## Step 4: Build and Push Docker Image to ECR (Manual Steps)\n",
    "> These steps must be executed in a terminal with Docker and AWS CLI configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shell commands (to be run manually in terminal):\n",
    "# aws ecr create-repository --repository-name minilm-lambda\n",
    "# $(aws ecr get-login --no-include-email)\n",
    "# docker build -t minilm-lambda .\n",
    "# docker tag minilm-lambda:latest <aws_account_id>.dkr.ecr.<region>.amazonaws.com/minilm-lambda:latest\n",
    "# docker push <aws_account_id>.dkr.ecr.<region>.amazonaws.com/minilm-lambda:latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc68eb3",
   "metadata": {},
   "source": [
    "## Step 5: Create Lambda + API Gateway via Terraform (Reference Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c80663",
   "metadata": {},
   "outputs": [],
   "source": [
    "terraform_code = '''\n",
    "resource \"aws_lambda_function\" \"qa_minilm_lambda\" {\n",
    "  function_name = \"qa-minilm\"\n",
    "  role          = aws_iam_role.lambda_exec.arn\n",
    "  package_type  = \"Image\"\n",
    "  image_uri     = \"<your_ecr_image_uri>\"\n",
    "  timeout       = 15\n",
    "  memory_size   = 1024\n",
    "}\n",
    "\n",
    "resource \"aws_apigatewayv2_api\" \"qa_api\" {\n",
    "  name          = \"QAAPI\"\n",
    "  protocol_type = \"HTTP\"\n",
    "}\n",
    "\n",
    "resource \"aws_apigatewayv2_integration\" \"qa_integration\" {\n",
    "  api_id           = aws_apigatewayv2_api.qa_api.id\n",
    "  integration_type = \"AWS_PROXY\"\n",
    "  integration_uri  = aws_lambda_function.qa_minilm_lambda.invoke_arn\n",
    "  integration_method = \"POST\"\n",
    "}\n",
    "'''\n",
    "print(terraform_code)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
