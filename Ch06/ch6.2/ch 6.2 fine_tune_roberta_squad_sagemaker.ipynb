{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d1a9c0",
   "metadata": {},
   "source": [
    "# Fine-Tuning RoBERTa on SQuAD Using SageMaker\n",
    "This notebook demonstrates how to fine-tune a Hugging Face RoBERTa model on the SQuAD dataset using Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets sagemaker --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e426875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "print(f\"Using bucket: {bucket}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a370d",
   "metadata": {},
   "source": [
    "## Load and Preprocess the SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac352f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "# Save to local files for SageMaker input\n",
    "train_file = \"train.json\"\n",
    "validation_file = \"validation.json\"\n",
    "dataset[\"train\"].to_json(train_file)\n",
    "dataset[\"validation\"].to_json(validation_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff356d",
   "metadata": {},
   "source": [
    "## Upload Dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = \"qa-squad-data\"\n",
    "s3_train_path = sess.upload_data(train_file, bucket=bucket, key_prefix=f\"{s3_prefix}/train\")\n",
    "s3_val_path = sess.upload_data(validation_file, bucket=bucket, key_prefix=f\"{s3_prefix}/validation\")\n",
    "print(f\"Train path: {s3_train_path}\\nVal path: {s3_val_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3cae3",
   "metadata": {},
   "source": [
    "## Define Hugging Face Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a7fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"model_name_or_path\": \"roberta-base\",\n",
    "    \"dataset_name\": \"squad\",\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"per_device_train_batch_size\": 8,\n",
    "    \"per_device_eval_batch_size\": 8,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_train_epochs\": 2,\n",
    "    \"max_seq_length\": 384,\n",
    "    \"doc_stride\": 128,\n",
    "    \"output_dir\": \"/opt/ml/model\"\n",
    "}\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./scripts\",\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    transformers_version=\"4.17\",\n",
    "    pytorch_version=\"1.10\",\n",
    "    py_version=\"py38\",\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "huggingface_estimator.fit({\n",
    "    \"train\": s3_train_path,\n",
    "    \"validation\": s3_val_path\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c3415",
   "metadata": {},
   "source": [
    "## Deploy the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81696cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bb28a3",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb826bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning models quickly.\"\n",
    "question = \"What is Amazon SageMaker?\"\n",
    "\n",
    "response = predictor.predict({\n",
    "    \"inputs\": {\n",
    "        \"question\": question,\n",
    "        \"context\": context\n",
    "    }\n",
    "})\n",
    "\n",
    "print(\"Answer:\", response)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
