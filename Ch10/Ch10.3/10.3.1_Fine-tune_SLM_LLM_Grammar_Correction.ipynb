{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50df4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install transformers datasets accelerate sentencepiece torch evaluate rouge_score\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Model Selection & Data Preparation ---\n",
    "# Choose a model. 't5-small' is an SLM, 't5-base' is a larger option.\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Create a small, illustrative dataset for fine-tuning.\n",
    "# In a real application, you'd load a much larger, diverse dataset.\n",
    "raw_data = {\n",
    "    \"incorrect\": [\n",
    "        \"I has went to the store.\",\n",
    "        \"They is planning a party.\",\n",
    "        \"She go to the gym every day.\",\n",
    "        \"The boy are playing in the park.\",\n",
    "        \"He dont like to eat apples.\",\n",
    "        \"I didn't liked the movie.\",\n",
    "        \"The cat sleep on the chair.\",\n",
    "    ],\n",
    "    \"correct\": [\n",
    "        \"I have gone to the store.\",\n",
    "        \"They are planning a party.\",\n",
    "        \"She goes to the gym every day.\",\n",
    "        \"The boys are playing in the park.\",\n",
    "        \"He doesn't like to eat apples.\",\n",
    "        \"I didn't like the movie.\",\n",
    "        \"The cat sleeps on the chair.\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(raw_data)\n",
    "# Split the dataset into train and validation sets\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']\n",
    "\n",
    "prefix = \"grammar correction: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + text for text in examples[\"incorrect\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"correct\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# --- 2. Training and Evaluation ---\n",
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # Decode predictions and labels\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE metric\n",
    "    rouge_results = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # BLEU metric\n",
    "    bleu_results = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Combine results\n",
    "    result = {**rouge_results, **bleu_results}\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5_grammar_correction\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "model.save_pretrained(\"./fine_tuned_t5_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_t5_model\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
