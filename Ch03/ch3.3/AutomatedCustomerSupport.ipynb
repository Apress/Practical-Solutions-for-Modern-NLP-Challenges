{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Customer Support using AWS SageMaker\n",
    "\n",
    "This notebook demonstrates two approaches for automating customer support queries:\n",
    "\n",
    "1. **RoBERTa for Complex Queries:**\n",
    "   - Leverages AWS SageMaker for scalable, production-grade inference.\n",
    "   - Ideal for complex customer queries requiring deep contextual understanding (using 5 intent classes).\n",
    "\n",
    "2. **DistilBERT for Fast, Simple Queries:**\n",
    "   - Performs local inference using DistilBERT, optimized for low latency.\n",
    "   - Suitable for straightforward queries like checking account balances or order statuses (using 3 intent classes).\n",
    "\n",
    "Detailed comments and explanations are provided in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3              # AWS SDK for Python to interact with AWS services\n",
    "import json               # To convert Python objects to JSON format\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification  # RoBERTa for intent classification\n",
    "import torch              # PyTorch for tensor operations\n",
    "\n",
    "# Load the pre-trained RoBERTa tokenizer and model for intent classification\n",
    "# 'num_labels=5' indicates five different customer support intents (e.g., order change, refund, inquiry, etc.)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=5)\n",
    "\n",
    "# Define example customer queries for complex query processing\n",
    "queries = [\n",
    "    \"How can I change my order?\",\n",
    "    \"I need help with a refund.\"\n",
    "]\n",
    "\n",
    "# Tokenize the input queries\n",
    "# - padding=True: Pads queries to ensure uniform length\n",
    "# - truncation=True: Truncates queries exceeding the maximum allowed length\n",
    "# - return_tensors=\"pt\": Returns the results as PyTorch tensors\n",
    "inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Convert tensor of input IDs to a list and then to a JSON formatted payload\n",
    "payload = json.dumps({\"input_ids\": inputs['input_ids'].tolist()})\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "# Specify the SageMaker endpoint name (ensure this matches your deployed endpoint)\n",
    "endpoint_name = \"customer-support-endpoint\"\n",
    "\n",
    "try:\n",
    "    # Invoke the SageMaker endpoint with the JSON payload\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=payload\n",
    "    )\n",
    "\n",
    "    # Read and decode the response from the endpoint\n",
    "    result = response['Body'].read().decode('utf-8')\n",
    "    print(\"SageMaker Endpoint Response:\", result)\n",
    "except Exception as e:\n",
    "    # Print any errors that occur during invocation\n",
    "    print(\"Error invoking SageMaker endpoint:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBERT for Fast, Simple Customer Queries\n",
    "\n",
    "In this section, we perform local inference using DistilBERT. This model is optimized for speed and lower resource usage, making it ideal for simple queries like checking account balances or order statuses. We use three intent classes (for example: 0 for Account Balance, 1 for Order Status, and 2 for Product Info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DistilBERT tokenizer and model for intent classification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load the pre-trained DistilBERT tokenizer and model\n",
    "# 'num_labels=3' sets up classification for three types of intents\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Define example customer queries for simple query processing\n",
    "queries = [\n",
    "    \"What is my account balance?\",\n",
    "    \"Where is my order?\"\n",
    "]\n",
    "\n",
    "# Tokenize the queries\n",
    "inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Run inference without gradient calculation to speed up the process\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    # The model outputs raw logits; we take the argmax to select the predicted intent class\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Print the sentiment predictions\n",
    "# Convention: 0 indicates Account Balance, 1 indicates Order Status, 2 indicates Product Info\n",
    "print(\"DistilBERT Intent Predictions:\", predictions.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook demonstrated two methods for automating customer support queries:\n",
    "\n",
    "1. **RoBERTa on AWS SageMaker:**\n",
    "   - Suited for handling complex customer queries that require deep contextual understanding.\n",
    "   - Integrated with AWS services for scalable inference (using a SageMaker endpoint).\n",
    "\n",
    "2. **DistilBERT for Local Inference:**\n",
    "   - Optimized for fast, low-latency inference for simpler queries.\n",
    "   - Runs directly on local resources, making it suitable for on-device applications.\n",
    "\n",
    "These approaches can be integrated with AWS Lex or AWS Lambda to build comprehensive automated customer support systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
