{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIW-Rkze3_kV"
      },
      "outputs": [],
      "source": [
        "#ROUGE & BERTScore\n",
        "\n",
        "REST API endpoint at http://127.0.0.1:8000/summarize/ where you can POST articles and receive summaries.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "rouge = load(\"rouge\")\n",
        "bert_score = load(\"bertscore\")\n",
        "rouge_results = rouge.compute(predictions=preds, references=refs)\n",
        "bert_results = bert_score.compute(predictions=preds, references=refs, lang=\"en\")\n",
        "print(f\"ROUGE-L: {rouge_results['rougeL']}, BERTScore F1: {bert_results['f1']}\")\n",
        "\n",
        "Example: Latency Measurement\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "_ = model.generate(**inputs)\n",
        "end = time.time()\n",
        "latency = (end - start) / len(inputs[\"input_ids\"])\n",
        "print(f\"Average latency per summary: {latency:.4f} seconds\")\n",
        "\n",
        "\n",
        "summarization_metrics.ipynb\n",
        "\n",
        "*** code ****\n",
        "\n",
        "pip install transformers datasets evaluate bert-score rouge_score\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "from bert_score import score\n",
        "from rouge_score import rouge_scorer\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\", split=\"test[:1%]\")\n",
        "\n",
        "predictions = []\n",
        "for article in dataset[\"article\"]:\n",
        "    summary = summarizer(article, max_length=150, min_length=50, do_sample=False)\n",
        "    predictions.append(summary[0][\"summary_text\"])\n",
        "\n",
        "rouge_metric = load(\"rouge\")\n",
        "rouge_results = rouge_metric.compute(predictions=predictions, references=dataset[\"highlights\"])\n",
        "print(f\"ROUGE Score: {rouge_results}\")\n",
        "\n",
        "P, R, F1 = score(predictions, dataset[\"highlights\"], lang=\"en\")\n",
        "print(f\"BERTScore F1: {F1.mean():.4f}\")\n",
        "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
        "rouge_l_scores = [scorer.score(ref, pred)[\"rougeL\"].fmeasure for ref, pred in zip(dataset[\"highlights\"], predictions)]\n",
        "average_rouge_l = sum(rouge_l_scores) / len(rouge_l_scores)\n",
        "print(f\"Average ROUGE-L F1: {average_rouge_l:.4f}\")\n",
        "\n",
        "bitnet_summarization_deployment.ipynb\n",
        "\n",
        "pip install transformers bitnet\n",
        "\n",
        "from bitnet import BitNetForCausalLM, BitNetTokenizer\n",
        "\n",
        "model = BitNetForCausalLM.from_pretrained(\"microsoft/bitnet-b1_58-2B\")\n",
        "tokenizer = BitNetTokenizer.from_pretrained(\"microsoft/bitnet-b1_58-2B\")\n",
        "# Define Summarization Function\n",
        "def summarize_text(text, model, tokenizer, max_length=150):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=max_length, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "article = \"Your long article text here...\"\n",
        "summary = summarize_text(article, model, tokenizer)\n",
        "print(\"Summary:\", summary)\n",
        "pip install fastapi uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class Article(BaseModel):\n",
        "    text: str\n",
        "\n",
        "@app.post(\"/summarize/\")\n",
        "def create_summary(article: Article):\n",
        "    summary = summarize_text(article.text, model, tokenizer)\n",
        "    return {\"summary\": summary}\n",
        "uvicorn app:app â€“reload\n"
      ],
      "metadata": {
        "id": "QZjW_PDc4Esk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}