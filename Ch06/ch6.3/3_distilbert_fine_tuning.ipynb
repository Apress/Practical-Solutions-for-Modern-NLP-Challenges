{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd333661",
   "metadata": {},
   "source": [
    "\n",
    "# 6.3.3 - Fine-Tuning DistilBERT for Extractive QA\n",
    "\n",
    "In this notebook, we fine-tune DistilBERT for extractive Question Answering using the SQuAD dataset.\n",
    "\n",
    "We'll cover:\n",
    "- Model and tokenizer setup\n",
    "- Dataset loading and preprocessing\n",
    "- Creating start/end token labels\n",
    "- Training using Hugging Face `Trainer`\n",
    "- Evaluation and inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ce37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers datasets accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fefad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_dataset(\"squad\")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_function(example):\n",
    "    inputs = tokenizer(example[\"question\"], example[\"context\"], truncation=True, padding=\"max_length\", max_length=384, return_offsets_mapping=True)\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answer = example[\"answers\"][\"text\"][0]\n",
    "    answer_start = example[\"answers\"][\"answer_start\"][0]\n",
    "    answer_end = answer_start + len(answer)\n",
    "\n",
    "    start_position = end_position = 0\n",
    "    for i, (start, end) in enumerate(offset_mapping):\n",
    "        if start <= answer_start < end:\n",
    "            start_position = i\n",
    "        if start < answer_end <= end:\n",
    "            end_position = i\n",
    "\n",
    "    inputs[\"start_positions\"] = start_position\n",
    "    inputs[\"end_positions\"] = end_position\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b37de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=False)\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "val_dataset = tokenized_dataset[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilbert-qa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d78d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_pretrained(\"./distilbert-finetuned-qa\")\n",
    "tokenizer.save_pretrained(\"./distilbert-finetuned-qa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context = \"Albert Einstein developed the theory of relativity in the early 20th century.\"\n",
    "question = \"Who developed the theory of relativity?\"\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\", max_length=384, truncation=True, padding=\"max_length\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "start_index = torch.argmax(start_logits)\n",
    "end_index = torch.argmax(end_logits) + 1\n",
    "tokens = inputs[\"input_ids\"][0][start_index:end_index]\n",
    "answer = tokenizer.decode(tokens)\n",
    "\n",
    "print(\"Extracted Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
