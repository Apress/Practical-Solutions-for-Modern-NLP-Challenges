{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Customer Support Chatbot (8.4.1 Use Case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain chromadb transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFaceHub, HuggingFaceEndpoint\n",
    "from transformers import pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_content = \"\"\"Customer Support FAQs:\n",
    "\n",
    "Q: How can I reset my password?\n",
    "A: To reset your password, click on \\\"Forgot Password\\\" on the login page, then follow the instructions sent to your email.\n",
    "\n",
    "Q: How do I update my contact information?\n",
    "A: To update your contact info, navigate to your account settings, then edit your personal details such as phone number or address.\n",
    "\n",
    "Q: What should I do if my account is locked?\n",
    "A: If your account is locked, please wait 15 minutes and try again. If the issue persists, contact our support team to unlock your account.\n",
    "\"\"\"\n",
    "with open(\"support_faq_en.txt\", \"w\") as f:\n",
    "    f.write(faq_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"support_faq_en.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "vector_store = Chroma.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_es_to_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "translator_en_to_es = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translator_fr_to_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator_en_to_fr = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_extractive = pipeline(\"question-answering\", model=\"distilbert-base-multilingual-cased-distilled-squad\")\n",
    "gemma_llm = None\n",
    "bitnet_llm = None\n",
    "try:\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your_huggingface_api_token\"\n",
    "    bitnet_llm = HuggingFaceHub(repo_id=\"microsoft/bitnet-b1.58-2B-4T\", model_kwargs={\"temperature\": 0.2, \"max_new_tokens\": 256})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import List, Optional\n",
    "from langchain.schema import Generation\n",
    "\n",
    "class QAExtractiveLLM(LLM):\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        if \"Q:\" in prompt and \"A:\" in prompt:\n",
    "            parts = prompt.split(\"Q:\")\n",
    "            context = parts[0]\n",
    "            question = parts[1].split(\"A:\")[0].strip()\n",
    "        else:\n",
    "            context = prompt\n",
    "            question = prompt\n",
    "        result = qa_extractive(question=question, context=context)\n",
    "        return result['answer']\n",
    "    def _identifying_params(self): return {}\n",
    "    @property\n",
    "    def _llm_type(self): return \"custom-extractive-qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive_chain = RetrievalQA.from_chain_type(llm=QAExtractiveLLM(), chain_type=\"stuff\", retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))\n",
    "generative_chain = None\n",
    "if bitnet_llm is not None:\n",
    "    generative_chain = RetrievalQA.from_chain_type(llm=bitnet_llm, chain_type=\"stuff\", retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(question: str) -> str:\n",
    "    q_lower = question.lower()\n",
    "    if \"¿\" in question or \"cómo\" in q_lower:\n",
    "        return \"es\"\n",
    "    elif \"comment\" in q_lower or \"ét\" in q_lower or \"é\" in q_lower:\n",
    "        return \"fr\"\n",
    "    else:\n",
    "        return \"en\"\n",
    "\n",
    "def ask_question_extractive(question: str):\n",
    "    lang = detect_language(question)\n",
    "    original_question = question\n",
    "    if lang == \"es\":\n",
    "        question = translator_es_to_en(question)[0]['translation_text']\n",
    "    elif lang == \"fr\":\n",
    "        question = translator_fr_to_en(question)[0]['translation_text']\n",
    "    answer_en = extractive_chain.run(question)\n",
    "    if lang == \"es\":\n",
    "        answer_final = translator_en_to_es(answer_en)[0]['translation_text']\n",
    "    elif lang == \"fr\":\n",
    "        answer_final = translator_en_to_fr(answer_en)[0]['translation_text']\n",
    "    else:\n",
    "        answer_final = answer_en\n",
    "    print(f\"Question ({lang}): {original_question}\")\n",
    "    print(f\"Answer ({lang}): {answer_final}\\n\")\n",
    "    return answer_final\n",
    "\n",
    "def ask_question_generative(question: str):\n",
    "    if generative_chain is None:\n",
    "        print(\"Generative LLM not available. Using extractive QA instead.\")\n",
    "        return ask_question_extractive(question)\n",
    "    lang = detect_language(question)\n",
    "    original_question = question\n",
    "    if lang == \"es\":\n",
    "        question = translator_es_to_en(question)[0]['translation_text']\n",
    "    elif lang == \"fr\":\n",
    "        question = translator_fr_to_en(question)[0]['translation_text']\n",
    "    answer_en = generative_chain.run(question)\n",
    "    if lang == \"es\":\n",
    "        answer_final = translator_en_to_es(answer_en)[0]['translation_text']\n",
    "    elif lang == \"fr\":\n",
    "        answer_final = translator_en_to_fr(answer_en)[0]['translation_text']\n",
    "    else:\n",
    "        answer_final = answer_en\n",
    "    print(f\"Question ({lang}): {original_question}\")\n",
    "    print(f\"Answer ({lang}): {answer_final}\\n\")\n",
    "    return answer_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test examples\n",
    "ask_question_extractive(\"¿Cómo puedo restablecer mi contraseña?\")\n",
    "ask_question_extractive(\"Que dois-je faire si mon compte est verrouillé?\")\n",
    "ask_question_generative(\"¿Cómo puedo restablecer mi contraseña?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
