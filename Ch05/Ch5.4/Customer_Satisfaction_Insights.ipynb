{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342b8df8",
   "metadata": {},
   "source": [
    "# Customer Satisfaction Insights - Small LLM Exploration\n",
    "\n",
    "This notebook covers customer sentiment insights using a cost-effective Small Language Model (SLM), focusing on deployment-friendly architectures for edge and mobile applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b638837",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers datasets flask sklearn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a65b1",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset as an example (IMDB)\n",
    "dataset = load_dataset('imdb', split='train[:5000]')\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf4b90",
   "metadata": {},
   "source": [
    "## Model Fine-tuning for Sentiment Analysis (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2)\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True)\n",
    "\n",
    "class FeedbackDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = FeedbackDataset(train_encodings, y_train.tolist())\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "from transformers import AdamW\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(2):  # fewer epochs for brevity\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8517a",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182540c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_dataset = FeedbackDataset(test_encodings, y_test.tolist())\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "        true_labels.extend(inputs['labels'].cpu().numpy())\n",
    "\n",
    "print(classification_report(true_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42316f94",
   "metadata": {},
   "source": [
    "## Deployment via Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    inputs = tokenizer(data['text'], return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    pred = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    sentiment = 'Positive' if pred == 1 else 'Negative'\n",
    "    return jsonify({'sentiment': sentiment})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a207d",
   "metadata": {},
   "source": [
    "## Dockerization Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e553fd",
   "metadata": {},
   "source": [
    "\n",
    "Create a Dockerfile:\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY . .\n",
    "RUN pip install torch transformers flask\n",
    "\n",
    "EXPOSE 5000\n",
    "CMD [\"python\", \"app.py\"]\n",
    "```\n",
    "\n",
    "Build and run:\n",
    "\n",
    "```bash\n",
    "docker build -t customer-satisfaction-insights .\n",
    "docker run -p 5000:5000 customer-satisfaction-insights\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140dc6f",
   "metadata": {},
   "source": [
    "## Test Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd9bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "response = requests.post(\"http://localhost:5000/predict\", json={\"text\": \"This product is fantastic!\"})\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2a78f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides an end-to-end example of customer sentiment analysis using a small, cost-effective LLM, suitable for lightweight deployment scenarios like edge computing or mobile devices."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
