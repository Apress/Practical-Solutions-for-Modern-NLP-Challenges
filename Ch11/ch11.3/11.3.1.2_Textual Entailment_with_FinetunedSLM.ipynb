{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Create a mock dataset for legal textual entailment.\n",
    "# In practice, this would be a much larger, carefully curated dataset.\n",
    "# The format is \"premise: [legal clause] hypothesis: [legal statement]\"\n",
    "entailment_data = [\n",
    "    {\"premise\": \"This agreement shall be governed by the laws of the State of New York.\",\n",
    "     \"hypothesis\": \"The contract is subject to the jurisdiction of New York.\",\n",
    "     \"label\": \"entailment\"},\n",
    "    {\"premise\": \"The Company shall provide a guarantee.\",\n",
    "     \"hypothesis\": \"The Company is not required to provide a guarantee.\",\n",
    "     \"label\": \"contradiction\"},\n",
    "    {\"premise\": \"This is a confidentiality clause.\",\n",
    "     \"hypothesis\": \"The contract is about a sale of goods.\",\n",
    "     \"label\": \"neutral\"}\n",
    "]\n",
    "\n",
    "# 2. Define the SLM and tokenizer.\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 3. Pre-process the data for T5 fine-tuning.\n",
    "def preprocess_entailment_data(examples):\n",
    "    # T5 uses a text-to-text format. We format the input and output strings.\n",
    "    inputs = [f\"mnli premise: {p} hypothesis: {h}\" for p, h in zip(examples['premise'], examples['hypothesis'])]\n",
    "    outputs = [l for l in examples['label']]\n",
    "    \n",
    "    # Tokenize the inputs and outputs\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(outputs, max_length=16, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Convert data to a Hugging Face Dataset object\n",
    "dataset = Dataset.from_dict({\"premise\": [d['premise'] for d in entailment_data],\n",
    "                             \"hypothesis\": [d['hypothesis'] for d in entailment_data],\n",
    "                             \"label\": [d['label'] for d in entailment_data]})\n",
    "\n",
    "# Preprocess the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_entailment_data, batched=True)\n",
    "\n",
    "# 4. Set up the training arguments and Trainer.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./entailment_model\",\n",
    "    per_device_train_batch_size=2, # Small batch size due to the tiny dataset\n",
    "    num_train_epochs=5,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Fine-tune the model.\n",
    "# trainer.train()\n",
    "\n",
    "# --- Example of inference after training ---\n",
    "# To use the fine-tuned model for inference:\n",
    "# load_model = T5ForConditionalGeneration.from_pretrained(\"./entailment_model\")\n",
    "# load_tokenizer = T5Tokenizer.from_pretrained(\"./entailment_model\")\n",
    "#\n",
    "# def predict_entailment(premise, hypothesis):\n",
    "#     input_text = f\"mnli premise: {premise} hypothesis: {hypothesis}\"\n",
    "#     input_ids = load_tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "#     outputs = load_model.generate(input_ids)\n",
    "#     return load_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#\n",
    "# result = predict_entailment(\"The contract requires arbitration.\", \"The parties must resolve disputes via arbitration.\")\n",
    "# print(f\"Prediction: {result}\")v"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
