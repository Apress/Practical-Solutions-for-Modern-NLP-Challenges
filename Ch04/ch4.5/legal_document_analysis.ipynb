{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PjkI1ndMlWo"
   },
   "outputs": [],
   "source": [
    "# The SLM aids in tailoring the model responses effective to the use case.\n",
    "\n",
    "# Install necessary libraries\n",
    "# !pip install transformers datasets torch\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForTokenClassification\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained DistilBERT model and tokenizer for NER\n",
    "model_name = \"dbmdz/distilbert-base-uncased-finetuned-conll03-english\"  # Pre-trained DistilBERT model fine-tuned for NER\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Initialize NER pipeline\n",
    "nlp_ner = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Example of a legal document text\n",
    "legal_document = \"\"\"\n",
    "The plaintiff, John Doe, filed a lawsuit against XYZ Corporation for breach of contract on January 15, 2023. The complaint alleges that XYZ Corporation, based in New York, failed to fulfill its contractual obligations, leading to financial damages. The legal team representing John Doe is headed by Sarah Johnson, an attorney at Law Group LLC.\n",
    "\"\"\"\n",
    "\n",
    "# Use the pipeline to extract named entities from the legal document\n",
    "entities = nlp_ner(legal_document)\n",
    "\n",
    "# Print out the identified entities in the document\n",
    "print(\"Named Entities in Legal Document:\")\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Confidence: {entity['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NWKEE4JM5VM",
    "outputId": "ca459143-69da-4dea-b253-1ae054be314a"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390,
     "referenced_widgets": [
      "307f3c463eeb4c688cea75de8a681479",
      "a9d248be27fc48a59ebb69623f726d9b",
      "951d1b6755dc43a7b917dd56ca9da3e7",
      "16bc53391aee4bf6842a6c2f0452717e",
      "c76042b0cd434dae9d4c0dd7b74b52e2",
      "f126d5c0b325444bb76cf2bf3d88de19",
      "4972aa96763d4c658b91fd74ee08b6bc",
      "268c3879d2ec426da9668fac604993e2",
      "2742c029d69148bc82b17e23b088be98",
      "3c326b3a24674f4cbb01b0db4d9b5a4c",
      "dc3a677023d54b2c8505bc163bc343ad",
      "32636167e9e243d6bf3752808b828633",
      "03db85f3b898489daadb9bd071a1ea26",
      "9e5934a793934ca8b235a4e2d55ec9ec",
      "99c597c0659b437292a7d40582f6e6da",
      "c705d8d6c53a4c6e9c5cce5126f744fa",
      "334dcc3a4d824c37a7b992c68d7752ed",
      "da18a898f3ed456d8391b017b7b04927",
      "4182bd05eca446ca8b64497df42c602c",
      "8977fb2e27b2417da30a40074d61bad2",
      "508691f757b54fc9955a1d8b370d1fb5",
      "ee70ba32cac44680a1515b97ec2ea856",
      "0f7aa9d859224e62b99690aad84830a6",
      "1b4e7e829eff4ce9ae40ca99db29e01f",
      "88c52b8192bf489486fdc8302732e775",
      "6cce0d14792447ebb1ae56aa02cdd6ca",
      "25fd746568b54e35b98d576d0472fd5d",
      "e3b0e343ee114cbf8fe3d10a1acbe404",
      "bfb80eb3300249eda4aa35808715d20a",
      "167e140a3fd9494eb6e36ca422144e77",
      "bac7c8fb8f9548f0b495aa353681b3ac",
      "8a2270036a5443578b69153c887ea472",
      "41ca41466f7e4828b7a97b5c2ab03bed",
      "1f96fd6019544a66bfe912190f5eee81",
      "8041ba3f25f64164b685b68f7f0a1f52",
      "3e1a30fe37d74260b6bf5f99f93a0eae",
      "6aa269ca7cb64adeac6ae0e9111d92f0",
      "70dbfd3548f841c28bc28e106cf69ef5",
      "cbb7bb5af8e84483b0f38a3d33020138",
      "ad681b04b51a4ba397f433b7012e1784",
      "980d051170864009ae954641bc8e9e52",
      "072d99063d6b451aa373afe5be8bfeaa",
      "906bbde489ae40b9bb06c2662a9dde32",
      "1056c54fc02746ee9dc4c6fd4251d092",
      "ba73d7f9367b467fbe6af2c349604484",
      "e915711d5ae5481cace5af6ab5eedb8c",
      "7a123a17a6434a26bccfcb06a3ffb5f6",
      "bffe3b7af97b41b0837bc5df9aced69c",
      "f155920568de427690f4bdce2e19e6eb",
      "28754bc5ec73424ea015812e086adbb6",
      "a7d60f7a9d2f4f38966665db177b8b4e",
      "c2b89aaa658c48aea441e34c020d9dc8",
      "3d936ed1e0bd42ca893784a8daa90d9c",
      "81f87562b2764ff5afbb1620c5c496ff",
      "b0fd4934cc7941e6b0620c5fb46d97b8",
      "a98e7705f53242f598c41c4b05f70aaf",
      "99968e9f639e43cbb45a2881d6a371da",
      "f54e1d641bc742f3b27ead862200ae99",
      "da661cdd7d7b44a29ca084f15a3ae966",
      "351b5ae06b824c4596383ec9add3d52e",
      "8f2642176d4b43a99927ccbd6f97959b",
      "401f898180c445f49b932edf0b53715d",
      "6343193d2dc048fa834ef8fee13eeb79",
      "a6917bc6498644b4b8781381abee86ea",
      "8b6dbe74f7da41a2b0ad6861036ddf6d",
      "88e046386a474c3b8accbc052d06d8db"
     ]
    },
    "id": "29BFTPvMM-sW",
    "outputId": "f644a0be-d0ea-43d0-d699-02f7d6ac1d94"
   },
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizerFast, ElectraForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained ELECTRA model and tokenizer for NER\n",
    "model_name = \"google/electra-large-discriminator\"\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(model_name)\n",
    "model = ElectraForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Initialize NER pipeline\n",
    "nlp_ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgCdnZ-VNAaQ",
    "outputId": "24143384-4290-4ea3-abeb-27f04f8ec06c"
   },
   "outputs": [],
   "source": [
    "legal_document = \"\"\"\n",
    "The plaintiff, John Doe, filed a lawsuit against XYZ Corporation for breach of contract on January 15, 2023. The complaint alleges that XYZ Corporation, based in New York, failed to fulfill its contractual obligations, leading to financial damages. The legal team representing John Doe is headed by Sarah Johnson, an attorney at Law Group LLC.\n",
    "\"\"\"\n",
    "\n",
    "# Use the pipeline to extract named entities from the legal document\n",
    "entities = nlp_ner(legal_document)\n",
    "\n",
    "# Print out the identified entities in the document\n",
    "print(\"Named Entities in Legal Document:\")\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Confidence: {entity['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_nB1EMEOryw"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import ElectraTokenizerFast, ElectraForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Sample dataset (expanded with diverse examples)\n",
    "train_dataset = [\n",
    "    {\"text\": \"John Doe filed a lawsuit against XYZ Corporation.\", \"entities\": [{\"start\": 0, \"end\": 8, \"entity\": \"PERSON\"}, {\"start\": 22, \"end\": 36, \"entity\": \"ORG\"}]},\n",
    "    {\"text\": \"Sarah Johnson is an attorney at Law Group LLC.\", \"entities\": [{\"start\": 0, \"end\": 13, \"entity\": \"PERSON\"}, {\"start\": 28, \"end\": 39, \"entity\": \"ORG\"}]},\n",
    "    {\"text\": \"The contract was signed on January 15, 2023.\", \"entities\": [{\"start\": 20, \"end\": 30, \"entity\": \"DATE\"}]},\n",
    "    {\"text\": \"The breach of contract caused significant financial damages.\", \"entities\": [{\"start\": 4, \"end\": 19, \"entity\": \"LEGAL_ISSUE\"}]},\n",
    "    {\"text\": \"The court ruled in favor of the plaintiff.\", \"entities\": [{\"start\": 0, \"end\": 5, \"entity\": \"ORG\"}, {\"start\": 24, \"end\": 32, \"entity\": \"LEGAL_ROLE\"}]},\n",
    "    # ... add even more examples\n",
    "]\n",
    "\n",
    "\n",
    "# Load pre-trained ELECTRA model and tokenizer\n",
    "model_name = \"google/electra-large-discriminator\"\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Get unique entity labels\n",
    "unique_entities = set([entity[\"entity\"] for example in train_dataset for entity in example[\"entities\"]])\n",
    "num_labels = len(unique_entities)\n",
    "\n",
    "# Create label mapping\n",
    "label2id = {label: i for i, label in enumerate(unique_entities)}\n",
    "id2label = {i: label for i, label in enumerate(unique_entities)}\n",
    "\n",
    "# Load model with correct number of labels\n",
    "model = ElectraForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "# Function to tokenize and format data\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    labels = []\n",
    "    for i, example in enumerate(examples[\"entities\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # Check if the current word is within any entity span\n",
    "                entity_id = -100  # Default to -100 (ignore)\n",
    "                for entity_info in examples[\"entities\"][i]: # Iterate through entities for this example\n",
    "                    if entity_info[\"start\"] <= word_idx < entity_info[\"end\"]:\n",
    "                        entity_id = label2id[entity_info[\"entity\"]]\n",
    "                        break  # Found the entity, stop searching\n",
    "                label_ids.append(entity_id)  # Append the entity ID (or -100)\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize dataset\n",
    "import datasets\n",
    "train_dataset = datasets.Dataset.from_list(train_dataset)\n",
    "tokenized_datasets = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Fine-tuning arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    run_name=\"my_legal_ner_run\",  # Set a distinct run name\n",
    "    # ... other training arguments\n",
    ")\n",
    "\n",
    "# Create Trainer and fine-tune\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    # ... (eval_dataset if available)\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./fine_tuned_model\")\n",
    "\n",
    "fine_tuned_model = ElectraForTokenClassification.from_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "\n",
    "# Quantization (dynamic)\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "torch.save(quantized_model.state_dict(), \"./quantized_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azFY4v44SRwf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inference and time measurement\n",
    "def measure_inference_time(model, text):\n",
    "    start_time = time.time()\n",
    "    nlp_ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "    entities = nlp_ner(text)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "legal_document = \"John Doe filed a lawsuit against XYZ Corporation.\"\n",
    "\n",
    "# Before fine-tuning and quantization\n",
    "before_time = measure_inference_time(model, legal_document)\n",
    "\n",
    "# After fine-tuning and quantization\n",
    "fine_tuned_model = ElectraForTokenClassification.from_pretrained(\"./fine_tuned_model\")\n",
    "fine_tuned_model.load_state_dict(torch.load(\"./quantized_model.pth\"))\n",
    "\n",
    "after_time = measure_inference_time(fine_tuned_model, legal_document)\n",
    "\n",
    "# Inference time delta\n",
    "delta = before_time - after_time\n",
    "print(f\"Inference time delta: {delta:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9Mlc9UZUEQY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
