{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd6QgvAlPfKF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import json\n",
        "import re\n",
        "import PyPDF2\n",
        "from typing import Dict, Any\n",
        "from transformers import pipeline\n",
        "from langchain.agents import Tool\n",
        "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "from langchain.tools import HumanInputRun\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# Initialize DuckDuckGo Search Tool (make sure it has the proper structure)\n",
        "# search_tool = Tool(\n",
        "#     name=\"DuckDuckGo Search\",\n",
        "#     func=DuckDuckGoSearchAPIWrapper().run,\n",
        "#     description=\"A tool for searching the web using DuckDuckGo.\"\n",
        "# )\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"DuckDuckGo Search\",\n",
        "    func=DuckDuckGoSearchAPIWrapper().run,\n",
        "    description=\"A tool for searching the web using DuckDuckGo.\"\n",
        ")\n",
        "\n",
        "search_query = \"AI Developer job posting\"\n",
        "search_tool_input = {\"query\": search_query}\n",
        "\n",
        "search_tool.run(search_tool_input)\n",
        "\n",
        "# Initialize OpenAI Tool (wrap OpenAI correctly as a tool)\n",
        "openai_tool = Tool(\n",
        "    name=\"OpenAI\",\n",
        "    func=lambda query: llm.run(query),\n",
        "    description=\"A tool for generating text using OpenAI's language model.\"\n",
        ")\n",
        "\n",
        "human_tool = Tool(\n",
        "    name=\"Human Input\",\n",
        "    func=HumanInputRun().run,\n",
        "    description=\"A tool that interacts with humans to get input during the process.\"\n",
        ")\n",
        "\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "# Resume parsing fun\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error extracting text from PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Initialize NER\n",
        "ner_pipeline = pipeline(\"ner\", model='dbmdz/bert-large-cased-finetuned-conll03-english')\n",
        "\n",
        "def parse_resume(resume_text: str) -> Dict[str, Any]:\n",
        "    entities = ner_pipeline(resume_text)\n",
        "\n",
        "    parsed_data = {\n",
        "        \"Name\": [],\n",
        "        \"Job Title\": [],\n",
        "        \"Company\": [],\n",
        "        \"Email\": [],\n",
        "        \"Skills\": [],\n",
        "        \"Education\": [],\n",
        "        \"Experience\": []\n",
        "    }\n",
        "\n",
        "    current_entity = None\n",
        "    current_text = \"\"\n",
        "\n",
        "    for entity in entities:\n",
        "        if entity['entity'].startswith('B-'):\n",
        "            if current_entity:\n",
        "                parsed_data[current_entity].append(current_text.strip())\n",
        "            current_entity = entity['entity'][2:]\n",
        "            current_text = entity['word']\n",
        "        elif entity['entity'].startswith('I-') and current_entity:\n",
        "            current_text += \" \" + entity['word']\n",
        "        else:\n",
        "            if current_entity:\n",
        "                parsed_data[current_entity].append(current_text.strip())\n",
        "            current_entity = None\n",
        "            current_text = \"\"\n",
        "\n",
        "        if '@' in entity['word']:\n",
        "            parsed_data[\"Email\"].append(entity['word'])\n",
        "\n",
        "\n",
        "    for key in parsed_data:\n",
        "        parsed_data[key] = list(set(parsed_data[key]))\n",
        "        if len(parsed_data[key]) == 1:\n",
        "            parsed_data[key] = parsed_data[key][0]\n",
        "\n",
        "\n",
        "    skills = re.findall(r'\\b(?:Python|Java|C\\+\\+|JavaScript|Machine Learning|NLP|AI|Pyspark|LLM|GenAI)\\b', resume_text)\n",
        "    parsed_data[\"Skills\"] = list(set(skills))\n",
        "\n",
        "    return parsed_data\n",
        "\n",
        "\n",
        "tech_job_researcher = Agent(\n",
        "    role='Tech Job Researcher',\n",
        "    goal='Analyze job postings to extract key requirements and skills',\n",
        "    backstory=\"You are an AI specialized in analyzing tech job postings. Your expertise lies in identifying crucial skills, qualifications, and requirements for various tech positions.\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[search_tool, openai_tool]  # Now using the wrapped OpenAI tool\n",
        ")\n",
        "\n",
        "personal_profiler = Agent(\n",
        "    role='Personal Profiler',\n",
        "    goal='Examine candidate profiles and personal statements to extract key information',\n",
        "    backstory=\"You are an AI expert in understanding and profiling individuals based on their resumes, GitHub profiles, and personal statements. You excel at identifying unique skills and experiences.\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[openai_tool, human_tool]  # Using the wrapped OpenAI tool and human tool\n",
        ")\n",
        "\n",
        "resume_strategist = Agent(\n",
        "    role='Resume Strategist',\n",
        "    goal='Align candidate experiences with job requirements to create tailored resumes',\n",
        "    backstory=\"You are an AI specialized in resume optimization. Your skill lies in matching candidate profiles with job requirements to create highly effective, tailored resumes.\",\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    tools=[openai_tool]\n",
        ")\n",
        "\n",
        "interview_preparer = Agent(\n",
        "    role='Interview Preparer',\n",
        "    goal='Generate targeted interview materials based on job requirements and candidate profiles',\n",
        "    backstory=\"You are an AI expert in preparing candidates for interviews. You excel at creating targeted questions and materials that align with both the job requirements and the candidate's profile.\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    tools=[openai_tool]\n",
        ")\n",
        "\n",
        "# Define Tasks# Define AI Agents and Tasks\n",
        "# Define AI Agents and Tasks\n",
        "analyze_job_posting = Task(\n",
        "    description=\"Analyze the given job posting URL and extract key requirements and skills.\",\n",
        "    agent=tech_job_researcher,\n",
        "    expected_output=\"A string containing the job requirements, skills, location, job title, and company.\"\n",
        ")\n",
        "\n",
        "profile_candidate = Task(\n",
        "    description=\"Examine the candidate's resume, GitHub profile, and personal statement to create a comprehensive profile.\",\n",
        "    agent=personal_profiler,\n",
        "    expected_output=\"A string containing the candidate's profile, including name, job title, skills, education, experience, and email.\"\n",
        ")\n",
        "\n",
        "create_tailored_resume = Task(\n",
        "    description=\"Using the job requirements and candidate profile, create a tailored resume.\",\n",
        "    agent=resume_strategist,\n",
        "    expected_output=\"A string containing the tailored resume for the candidate.\"\n",
        ")\n",
        "\n",
        "prepare_interview_materials = Task(\n",
        "    description=\"Generate interview questions and preparation materials based on the job requirements and candidate profile.\",\n",
        "    agent=interview_preparer,\n",
        "    expected_output=\"A string containing interview questions and preparation materials for the candidate.\"\n",
        ")\n",
        "\n",
        "\n",
        "# Create Crew\n",
        "resume_parsing_crew = Crew(\n",
        "    agents=[tech_job_researcher, personal_profiler, resume_strategist, interview_preparer],\n",
        "    tasks=[analyze_job_posting, profile_candidate, create_tailored_resume, prepare_interview_materials],\n",
        "    verbose=True,  # Set verbose to True for detailed logging\n",
        "    process=Process.sequential\n",
        ")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "     job_posting_url = \"https://www.lockheedmartinjobs.com/job/king-of-prussia/ai-machine-learning-engineer-stf/694/74728384000?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic\"\n",
        "    resume_pdf_path = \"/content/test/resume.pdf\"  # Replace with actual path\n",
        "    github_profile = \"https://github.com/xyz\"  # Replace with actual profile URL\n",
        "       personal_statement = \"I am a passionate Data scientist with 10 years of experience...\"\n",
        "\n",
        "\n",
        "    # Extract resume text\n",
        "    resume_text = extract_text_from_pdf(resume_pdf_path)\n",
        "\n",
        "    if resume_text:\n",
        "        # Parse resume\n",
        "        if resume_text:\n",
        "            parsed_resume = parse_resume(resume_text)\n",
        "            print(\"Parsed Resume Data:\")\n",
        "            print(json.dumps(parsed_resume, indent=2))\n",
        "        else:\n",
        "            print(\"Failed to extract text from the PDF.\")\n",
        "\n",
        "\n",
        "# Search for job posting\n",
        "        search_query = \"AI Machine learning engineer job posting\"\n",
        "        search_input = {\"query\": search_query}\n",
        "\n",
        "        search_tool = Tool(\n",
        "            name=\"DuckDuckGo Search\",\n",
        "            func=DuckDuckGoSearchAPIWrapper().run,\n",
        "            description=\"A tool for searching the web using DuckDuckGo.\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            job_posting_result = search_tool.run(search_input)\n",
        "            print(f\"Job Posting Result: {job_posting_result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during job posting search: {e}\")\n",
        "\n",
        "# Now, proceed with the tasks and agents, making sure to validate inputs before passing them\n",
        "\n",
        "        # Run the crew\n",
        "        result = resume_parsing_crew.kickoff(\n",
        "            inputs={\n",
        "                \"job_posting_url\": job_posting_url,\n",
        "                \"parsed_resume\": parsed_resume,\n",
        "                \"github_profile\": github_profile,\n",
        "                \"personal_statement\": personal_statement\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(\"\\nCrew Execution Result:\")\n",
        "        print(result)\n",
        "    else:\n",
        "        print(\"Failed to extract text from the PDF.\")\n"
      ]
    }
  ]
}