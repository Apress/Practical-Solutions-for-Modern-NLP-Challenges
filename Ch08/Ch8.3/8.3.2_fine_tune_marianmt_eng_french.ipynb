{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fine-Tuning MarianMT on Custom Data \n",
    "\n",
    "# datasets for loading and preprocessing data\n",
    "\n",
    "# transformers for the MarianMT model and training\n",
    "\n",
    "# Trainer API for training loop management\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install transformers datasets sentencepiece sacrebleu --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589922f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "\n",
    "[\n",
    "  { \"translation\": { \"en\": \"Hello, how are you?\", \"fr\": \"Bonjour, comment Ã§a va ?\" }},\n",
    "  { \"translation\": { \"en\": \"Good morning\", \"fr\": \"Bon matin\" }}\n",
    "]\n",
    "\n",
    "# save it as en_fr_dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16450ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Save as .py file - fine tuning the model for language translation \n",
    "\n",
    "from transformers import MarianTokenizer, MarianMTModel, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "# Define source and target languages\n",
    "SRC_LANG = \"en\"\n",
    "TGT_LANG = \"fr\"\n",
    "MODEL_NAME = f\"Helsinki-NLP/opus-mt-{SRC_LANG}-{TGT_LANG}\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = MarianTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = MarianMTModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load parallel dataset (assumes 'translation' key with src and tgt)\n",
    "raw_data = load_dataset(\"json\", data_files=\"en_fr_dataset.json\", split=\"train\")\n",
    "\n",
    "# Tokenization function\n",
    "def preprocess_function(example):\n",
    "    inputs = example[\"translation\"][SRC_LANG]\n",
    "    targets = example[\"translation\"][TGT_LANG]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_data = raw_data.map(preprocess_function, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Evaluation metric\n",
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    return bleu.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./marianmt_en_fr_finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data,\n",
    "    eval_dataset=tokenized_data,  # replace with validation set if available\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model(\"./marianmt_en_fr_finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c36618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script\n",
    "python fine_tune_marianmt.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for inference\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"./marianmt_en_fr_finetuned\", tokenizer=MODEL_NAME)\n",
    "result = translator(\"How can I help you?\", max_length=128)\n",
    "print(result[0][\"translation_text\"])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
