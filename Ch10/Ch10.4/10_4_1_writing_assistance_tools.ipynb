{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179b17a7",
   "metadata": {},
   "source": [
    "# Writing Assistance Tools: Text Correction using SLM and LLM\n",
    "\n",
    "This notebook implements a **writing assistance pipeline** focused on grammar and spelling correction, combining:\n",
    "- **Small Language Model (SLM)** for grammatical acceptability detection (using a DistilBERT variant fine-tuned on CoLA),\n",
    "- **Large Language Model / Sequence-to-Sequence model (LLM)** for generative correction (using T5-small fine-tuned for grammar correction).\n",
    "\n",
    "The pipeline demonstrates how to detect problematic sentences and propose corrected rewrites, and evaluates corrections using standard metrics such as BLEU, Levenshtein (edit) distance, and simple overlap-based scores.\n",
    "\n",
    "The design is modular so it can be extended to real datasets (e.g., JFLEG, BEA, CoNLL), integrated with user-facing interfaces, or deployed in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852155c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this cell once)\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Core NLP / evaluation libraries\n",
    "required = [\n",
    "    \"transformers>=4.30.0\",\n",
    "    \"datasets\",\n",
    "    \"evaluate\",\n",
    "    \"rouge_score\",\n",
    "    \"nltk\"\n",
    "]\n",
    "for pkg in required:\n",
    "    try:\n",
    "        __import__(pkg.split('>=')[0])\n",
    "    except ImportError:\n",
    "        install(pkg)\n",
    "\n",
    "# Download NLTK data needed\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DistilBertTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from evaluate import load as load_metric\n",
    "import math\n",
    "\n",
    "# Helper: simple Levenshtein distance implementation\n",
    "def levenshtein_distance(a: str, b: str) -> int:\n",
    "    # classic dynamic programming\n",
    "    n, m = len(a), len(b)\n",
    "    if n == 0:\n",
    "        return m\n",
    "    if m == 0:\n",
    "        return n\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = 0 if a[i - 1] == b[j - 1] else 1\n",
    "            dp[i][j] = min(\n",
    "                dp[i - 1][j] + 1,      # deletion\n",
    "                dp[i][j - 1] + 1,      # insertion\n",
    "                dp[i - 1][j - 1] + cost  # substitution\n",
    "            )\n",
    "    return dp[n][m]\n",
    "\n",
    "# Token-based similarity (optional)\n",
    "def word_overlap_score(pred: str, reference: str) -> float:\n",
    "    p_tokens = set(word_tokenize(pred.lower()))\n",
    "    r_tokens = set(word_tokenize(reference.lower()))\n",
    "    if not r_tokens:\n",
    "        return 0.0\n",
    "    overlap = p_tokens.intersection(r_tokens)\n",
    "    return len(overlap) / len(r_tokens)\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = load_metric('bleu')\n",
    "rouge = load_metric('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b79f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small synthetic dataset of erroneous -> corrected pairs\n",
    "examples = [\n",
    "    {\n",
    "        \"source\": \"She go to school every day.\",\n",
    "        \"target\": \"She goes to school every day.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"I has a meeting tomorrow.\",\n",
    "        \"target\": \"I have a meeting tomorrow.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"They is playing football.\",\n",
    "        \"target\": \"They are playing football.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"He don't like apples.\",\n",
    "        \"target\": \"He doesn't like apples.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"The cat chase the mouse.\",\n",
    "        \"target\": \"The cat chases the mouse.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"This sentences are wrong.\",\n",
    "        \"target\": \"These sentences are wrong.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"We was late to the party.\",\n",
    "        \"target\": \"We were late to the party.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"Your going to love it.\",\n",
    "        \"target\": \"You're going to love it.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"I will finished it soon.\",\n",
    "        \"target\": \"I will finish it soon.\"\n",
    "    },\n",
    "    {\n",
    "        \"source\": \"Its a beautiful day.\",\n",
    "        \"target\": \"It's a beautiful day.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_list([\n",
    "    {\n",
    "        \"input_text\": \"correct: \" + ex[\"source\"],\n",
    "        \"target_text\": ex[\"target\"]\n",
    "    }\n",
    "    for ex in examples\n",
    "])\n",
    "\n",
    "# Quick peek\n",
    "print('Sample example:', dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generative correction model: T5-small\n",
    "t5_model_name = \"t5-small\"\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name)\n",
    "\n",
    "# Load SLM for grammatical acceptability detection (CoLA)\n",
    "# We'll use a model fine-tuned on CoLA for acceptability judgments\n",
    "cola_model_name = \"textattack/distilbert-base-uncased-CoLA\"\n",
    "cola_tokenizer = DistilBertTokenizer.from_pretrained(cola_model_name)\n",
    "cola_model = AutoModelForSequenceClassification.from_pretrained(cola_model_name)\n",
    "cola_pipe = pipeline(\"text-classification\", model=cola_model, tokenizer=cola_tokenizer, return_all_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset for T5 training\n",
    "max_input_length = 64\n",
    "max_target_length = 64\n",
    "\n",
    "def preprocess_function(example):\n",
    "    model_inputs = t5_tokenizer(example['input_text'], truncation=True, padding='max_length',\n",
    "                                max_length=max_input_length)\n",
    "    with t5_tokenizer.as_target_tokenizer():\n",
    "        labels = t5_tokenizer(example['target_text'], truncation=True, padding='max_length',\n",
    "                              max_length=max_target_length)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=False)  # small, so batched=False is okay\n",
    "# Data collator handles padding properly\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=t5_tokenizer, model=t5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc442ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments (small scale for demonstration)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5-writing-assist\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    report_to=[]  # disable external logging (e.g., wandb) for portability\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=t5_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train (this is small, should finish quickly)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate correction with T5\n",
    "def correct_with_t5(sentence: str, num_beams: int = 3) -> str:\n",
    "    input_text = \"correct: \" + sentence\n",
    "    inputs = t5_tokenizer(input_text, return_tensors='pt', truncation=True, padding=True, max_length=64)\n",
    "    outputs = t5_model.generate(**inputs, num_beams=num_beams, max_length=64, early_stopping=True)\n",
    "    corrected = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected\n",
    "\n",
    "# Function to check grammatical acceptability using CoLA-model (SLM)\n",
    "def check_acceptability(sentence: str):\n",
    "    res = cola_pipe(sentence)\n",
    "    # The label is usually 'acceptable' vs 'unacceptable' depending on model; dsiplay raw\n",
    "    return res\n",
    "\n",
    "# Evaluate on synthetic dataset\n",
    "def evaluate_corrections(examples_list):\n",
    "    bleu_scores = []\n",
    "    edit_distances = []\n",
    "    overlap_scores = []\n",
    "    references = []\n",
    "    predictions = []\n",
    "    for ex in examples_list:\n",
    "        src = ex['source']\n",
    "        tgt = ex['target']\n",
    "        pred = correct_with_t5(src)\n",
    "        # BLEU expects list of references (tokenized) and prediction\n",
    "        ref_tokens = [tgt.split()]\n",
    "        pred_tokens = pred.split()\n",
    "        bleu_res = bleu.compute(predictions=[pred_tokens], references=[ref_tokens])\n",
    "        # Levenshtein on raw strings\n",
    "        ed = levenshtein_distance(pred, tgt)\n",
    "        overlap = word_overlap_score(pred, tgt)\n",
    "        bleu_scores.append(bleu_res['bleu'])\n",
    "        edit_distances.append(ed)\n",
    "        overlap_scores.append(overlap)\n",
    "        references.append(tgt)\n",
    "        predictions.append(pred)\n",
    "        print(f\"Source: {src}\\nTarget: {tgt}\\nPredicted: {pred}\\nBLEU: {bleu_res['bleu']:.3f}, Edit Distance: {ed}, Overlap: {overlap:.3f}\\n---\")\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_edit = sum(edit_distances) / len(edit_distances)\n",
    "    avg_overlap = sum(overlap_scores) / len(overlap_scores)\n",
    "    print(f\"\\nAverage BLEU: {avg_bleu:.3f}, Average Edit Distance: {avg_edit:.2f}, Average Overlap: {avg_overlap:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5cd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined writing assistance function\n",
    "def writing_assistant(sentence: str):\n",
    "    print(f\"Input Sentence: {sentence}\\n\")\n",
    "    acceptability = check_acceptability(sentence)\n",
    "    print(f\"Grammatical Acceptability (SLM): {acceptability}\\n\")\n",
    "    correction = correct_with_t5(sentence)\n",
    "    print(f\"T5 Suggestion: {correction}\\n\")\n",
    "    # Simple heuristic: if edit distance is small, suggest minor change, else full rewrite\n",
    "    ed = levenshtein_distance(correction, sentence)\n",
    "    if ed == 0:\n",
    "        print(\"No changes suggested by the generator.\")\n",
    "    else:\n",
    "        print(f\"Edit distance between input and suggestion: {ed}\") \n",
    "\n",
    "# Example usage\n",
    "print('--- Evaluation on synthetic dataset ---')\n",
    "evaluate_corrections(examples)\n",
    "\n",
    "print('\\n--- Writing assistant demos ---')\n",
    "writing_assistant(\"She dont like the movie.\")\n",
    "writing_assistant(\"I will go to the market yesterday.\")\n",
    "writing_assistant(\"He has a dogs.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
